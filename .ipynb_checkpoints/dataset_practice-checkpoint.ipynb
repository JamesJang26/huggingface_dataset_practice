{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2ba094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Downloading numpy-1.26.2-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-14.0.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.1.3-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting huggingface-hub>=0.18.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.3-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.18.0->datasets)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.18.0->datasets)\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 341.8/341.8 kB 22.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "   ---------------------------------------- 0.0/521.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 521.2/521.2 kB 34.1 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 115.3/115.3 kB ? eta 0:00:00\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 166.4/166.4 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl (364 kB)\n",
      "   ---------------------------------------- 0.0/364.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 364.8/364.8 kB 22.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "   ---------------------------------------- 0.0/311.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 311.7/311.7 kB 18.8 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.2-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.5/15.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.5/15.8 MB 31.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.5/15.8 MB 24.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 24.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.8 MB 23.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.7/15.8 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 6.1/15.8 MB 20.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 19.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.2/15.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.6/15.8 MB 18.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.2/15.8 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.7/15.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.1/15.8 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.8 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.2/15.8 MB 15.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.8 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.9/15.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.1/15.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.2/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.6/15.8 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.0/15.8 MB 9.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.3/15.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.7/15.8 MB 8.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 8.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.0/15.8 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading pyarrow-14.0.1-cp311-cp311-win_amd64.whl (24.6 MB)\n",
      "   ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/24.6 MB 12.5 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.7/24.6 MB 8.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.0/24.6 MB 8.3 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.4/24.6 MB 8.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.8/24.6 MB 8.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.2/24.6 MB 8.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.5/24.6 MB 9.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.8/24.6 MB 8.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.1/24.6 MB 8.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.4/24.6 MB 8.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.7/24.6 MB 8.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.0/24.6 MB 8.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/24.6 MB 7.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.5/24.6 MB 7.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.7/24.6 MB 7.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 4.9/24.6 MB 7.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.1/24.6 MB 7.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.4/24.6 MB 7.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.6/24.6 MB 7.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.9/24.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.2/24.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.5/24.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.7/24.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.0/24.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.2/24.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.4/24.6 MB 6.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.6/24.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.8/24.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.9/24.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.1/24.6 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.2/24.6 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.4/24.6 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.6/24.6 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.7/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.9/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.1/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.4/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.6/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.0/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.2/24.6 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.4/24.6 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.8/24.6 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.9/24.6 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.1/24.6 MB 5.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.3/24.6 MB 5.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.4/24.6 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.6/24.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.8/24.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.0/24.6 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.2/24.6 MB 5.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.4/24.6 MB 5.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.6/24.6 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.8/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.1/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.3/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.6/24.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.8/24.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.0/24.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.2/24.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.5/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.7/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.2/24.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.5/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.8/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.1/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.3/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.6/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.0/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.2/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.5/24.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.6 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.3/24.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.7/24.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.0/24.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.5/24.6 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.9/24.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.3/24.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.7/24.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.4/24.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.1/24.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.5/24.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.9/24.6 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.6 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.6 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/24.6 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.6/24.6 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.4/135.4 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading pandas-2.1.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/10.6 MB 12.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/10.6 MB 14.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.7/10.6 MB 13.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.2/10.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.8/10.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.3/10.6 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.9/10.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.4/10.6 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.0/10.6 MB 13.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.6/10.6 MB 13.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.6 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 14.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.1/10.6 MB 14.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.8/10.6 MB 14.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.3/10.6 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.0/10.6 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB ? eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 502.5/502.5 kB 15.4 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading yarl-1.9.3-cp311-cp311-win_amd64.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB ? eta 0:00:00\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, typing-extensions, tqdm, pyarrow-hotfix, numpy, multidict, fsspec, frozenlist, filelock, dill, yarl, pyarrow, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 datasets-2.15.0 dill-0.3.7 filelock-3.13.1 frozenlist-1.4.0 fsspec-2023.10.0 huggingface-hub-0.19.4 multidict-6.0.4 multiprocess-0.70.15 numpy-1.26.2 pandas-2.1.3 pyarrow-14.0.1 pyarrow-hotfix-0.6 pytz-2023.3.post1 tqdm-4.66.1 typing-extensions-4.8.0 tzdata-2023.3 xxhash-3.4.1 yarl-1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bd47b4-7cd0-4284-b3f1-14970546134f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2281689675.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -c \"from datasets import load_dataset; print(load_dataset('squad', split='train')[0])\"\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -c \"from datasets import load_dataset; print(load_dataset('squad', split='train')[0])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1970348e-3246-48be-9e28-ad2aedfe70c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets[audio] in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets[audio]) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[audio]) (6.0.1)\n",
      "Collecting soundfile>=0.12.1 (from datasets[audio])\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.0 MB 487.6 kB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 0.7/1.0 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting librosa (from datasets[audio])\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[audio]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[audio]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[audio]) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[audio]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets[audio]) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets[audio]) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[audio]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[audio]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[audio]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[audio]) (2023.11.17)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from tqdm>=4.62.1->datasets[audio]) (0.4.6)\n",
      "Collecting audioread>=2.1.9 (from librosa->datasets[audio])\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from librosa->datasets[audio])\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.4/60.4 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=0.20.0 (from librosa->datasets[audio])\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting joblib>=0.14 (from librosa->datasets[audio])\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from librosa->datasets[audio]) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa->datasets[audio])\n",
      "  Downloading numba-0.58.1-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting pooch>=1.0 (from librosa->datasets[audio])\n",
      "  Downloading pooch-1.8.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->datasets[audio])\n",
      "  Downloading soxr-0.3.7-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa->datasets[audio])\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->datasets[audio])\n",
      "  Downloading msgpack-1.0.7-cp311-cp311-win_amd64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets[audio]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets[audio]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets[audio]) (2023.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa->datasets[audio])\n",
      "  Downloading llvmlite-0.41.1-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pooch>=1.0->librosa->datasets[audio]) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.20.0->librosa->datasets[audio])\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "   ---------------------------------------- 0.0/253.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 253.7/253.7 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 302.2/302.2 kB 19.5 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Downloading msgpack-1.0.7-cp311-cp311-win_amd64.whl (222 kB)\n",
      "   ---------------------------------------- 0.0/222.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 222.9/222.9 kB ? eta 0:00:00\n",
      "Downloading numba-0.58.1-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.6/2.6 MB 83.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 55.2 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 33.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 33.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 33.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 33.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/9.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.4/9.2 MB 16.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.2 MB 20.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.2 MB 20.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.2 MB 20.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.2 MB 20.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.2 MB 20.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.2 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.2 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.9/44.1 MB 41.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.7/44.1 MB 39.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 5.2/44.1 MB 37.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.7/44.1 MB 35.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.0/44.1 MB 34.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.1/44.1 MB 34.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.7/44.1 MB 29.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.2/44.1 MB 27.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.8/44.1 MB 24.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.3/44.1 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.9/44.1 MB 21.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.5/44.1 MB 19.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 13.0/44.1 MB 18.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.6/44.1 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.1/44.1 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.7/44.1 MB 16.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.3/44.1 MB 15.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 15.7/44.1 MB 14.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.1/44.1 MB 13.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.4/44.1 MB 13.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.7/44.1 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.0/44.1 MB 12.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.4/44.1 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.9/44.1 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.3/44.1 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.7/44.1 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.2/44.1 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.6/44.1 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.1/44.1 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.6/44.1 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.2/44.1 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.6/44.1 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.0/44.1 MB 9.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.4/44.1 MB 9.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 22.9/44.1 MB 9.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.3/44.1 MB 9.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.8/44.1 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 24.4/44.1 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 24.9/44.1 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.4/44.1 MB 9.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.8/44.1 MB 9.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.3/44.1 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.7/44.1 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.1/44.1 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.5/44.1 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.0/44.1 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.5/44.1 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 28.8/44.1 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.3/44.1 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.7/44.1 MB 9.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.0/44.1 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.5/44.1 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.8/44.1 MB 9.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.1/44.1 MB 9.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.4/44.1 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.7/44.1 MB 8.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.9/44.1 MB 8.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.1/44.1 MB 8.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.4/44.1 MB 8.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.6/44.1 MB 8.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.8/44.1 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.1/44.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.4/44.1 MB 7.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.6/44.1 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.9/44.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.2/44.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.9/44.1 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.4/44.1 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.8/44.1 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.2/44.1 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.5/44.1 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.9/44.1 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.3/44.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.7/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.1/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.5/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.0/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.4/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.7/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.1/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.5/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.9/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.3/44.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.7/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.2/44.1 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.7/44.1 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.1/44.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.6/44.1 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading soxr-0.3.7-cp311-cp311-win_amd64.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 184.7/184.7 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.41.1-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/28.1 MB 10.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.8/28.1 MB 9.8 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.2/28.1 MB 9.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.7/28.1 MB 9.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.1/28.1 MB 9.7 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.7/28.1 MB 10.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.2/28.1 MB 10.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/28.1 MB 10.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.3/28.1 MB 10.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.9/28.1 MB 10.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 5.4/28.1 MB 10.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.9/28.1 MB 11.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.5/28.1 MB 11.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 7.0/28.1 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.3/28.1 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.8/28.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.3/28.1 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.8/28.1 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.4/28.1 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.8/28.1 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 10.4/28.1 MB 10.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.9/28.1 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.5/28.1 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 12.0/28.1 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 12.5/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 13.1/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.6/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.2/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.7/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 15.3/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 15.9/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.4/28.1 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 17.0/28.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 17.5/28.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 18.1/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.7/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.2/28.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.8/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 20.3/28.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.7/28.1 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 21.0/28.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.4/28.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.7/28.1 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 22.1/28.1 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.5/28.1 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.9/28.1 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.4/28.1 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.7/28.1 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.1/28.1 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.4/28.1 MB 9.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.8/28.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.2/28.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.7/28.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.0/28.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.5/28.1 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.9/28.1 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.6/28.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.8/28.1 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, soxr, scipy, msgpack, llvmlite, lazy-loader, joblib, audioread, soundfile, scikit-learn, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 joblib-1.3.2 lazy-loader-0.3 librosa-0.10.1 llvmlite-0.41.1 msgpack-1.0.7 numba-0.58.1 pooch-1.8.0 scikit-learn-1.3.2 scipy-1.11.4 soundfile-0.12.1 soxr-0.3.7 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets[audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2ff4b1-a65f-4f61-8e8f-5391dd087195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets[vision] in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets[vision]) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (0.19.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from datasets[vision]) (6.0.1)\n",
      "Collecting Pillow>=6.2.1 (from datasets[vision])\n",
      "  Downloading Pillow-10.1.0-cp311-cp311-win_amd64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[vision]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[vision]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[vision]) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[vision]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from aiohttp->datasets[vision]) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets[vision]) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets[vision]) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[vision]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[vision]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[vision]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests>=2.19.0->datasets[vision]) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from tqdm>=4.62.1->datasets[vision]) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets[vision]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets[vision]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from pandas->datasets[vision]) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[vision]) (1.16.0)\n",
      "Downloading Pillow-10.1.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.6 MB 960.0 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.0/2.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 23.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 20.8 MB/s eta 0:00:00\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-10.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets[vision]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbe11b-4795-40a7-a873-02dc10da4a2c",
   "metadata": {},
   "source": [
    "# 1. 데이터셋 정보 확인하고 다운받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97ecf4b-45a2-4f69-926a-87bab46970dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a625a2c616f74e5c9a70073113254516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f33aef203874d3ab6da842786878c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fe48e9c5aa482abe304c9cf2db2e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"wiki_bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4eb9f59-bc9d-4c2c-8bbb-3ca0ddafb2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This dataset gathers 728,321 biographies from wikipedia. It aims at evaluating text generation\\nalgorithms. For each article, we provide the first paragraph and the infobox (both tokenized).\\nFor each article, we extracted the first paragraph (text), the infobox (structured data). Each\\ninfobox is encoded as a list of (field name, field value) pairs. We used Stanford CoreNLP\\n(http://stanfordnlp.github.io/CoreNLP/) to preprocess the data, i.e. we broke the text into\\nsentences and tokenized both the text and the field values. The dataset was randomly split in\\nthree subsets train (80%), valid (10%), test (10%).\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6974ad-a43e-4e09-b1db-330e6c27a126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4199a6134674fb7a18bc3b49c4f2752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/15.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d4f2744d2643f4a7968719fbec75f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/25.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nDiffusionDB is the first large-scale text-to-image prompt dataset. It contains 2\\nmillion images generated by Stable Diffusion using prompts and hyperparameters\\nspecified by real users. The unprecedented scale and diversity of this\\nhuman-actuated dataset provide exciting research opportunities in understanding\\nthe interplay between prompts and generative models, detecting deepfakes, and\\ndesigning human-AI interaction tools to help users more easily use these models.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2 = load_dataset_builder(\"poloclub/diffusiondb\")\n",
    "ds2.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ff2d2b-9d68-4787-9981-6f69605a88a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': {'table': Sequence(feature={'column_header': Value(dtype='string', id=None), 'row_number': Value(dtype='int16', id=None), 'content': Value(dtype='string', id=None)}, length=-1, id=None),\n",
       "  'context': Value(dtype='string', id=None)},\n",
       " 'target_text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe3d4106-b058-4459-a106-446b7fbc4ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wiki_bio'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.builder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fda180f-131e-4d67-96d4-7c4acde2a028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@article{DBLP:journals/corr/LebretGA16,\\n  author    = {R{'{e}}mi Lebret and\\n               David Grangier and\\n               Michael Auli},\\n  title     = {Generating Text from Structured Data with Application to the Biography\\n               Domain},\\n  journal   = {CoRR},\\n  volume    = {abs/1603.07771},\\n  year      = {2016},\\n  url       = {http://arxiv.org/abs/1603.07771},\\n  archivePrefix = {arXiv},\\n  eprint    = {1603.07771},\\n  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},\\n  biburl    = {https://dblp.org/rec/journals/corr/LebretGA16.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691ca9a3-a289-42d1-8a77-77d173e57a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773869021"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder.info.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "925f9a80-bab9-4bc2-a50c-f67e066f71d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d77f4b5b774dfab678a57bb67046eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/334M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0847c9c06434c2397b40ecf5dfa6dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/582659 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddec9aa16a1451498962774f06846ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/72831 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5747c127759248d480977b9fd7e594de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split:   0%|          | 0/72831 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "d1 = load_dataset(\"wiki_bio\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3de0127-43e3-4f32-997c-864f802c8a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test', 'val']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "get_dataset_split_names(\"wiki_bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc929ca-fdfb-4322-81fc-664ad33727ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_text', 'target_text'],\n",
       "    num_rows: 582659\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b983c0c-0bc7-4534-8b97-92c40bc60fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_text', 'target_text'],\n",
       "    num_rows: 72831\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = load_dataset(\"wiki_bio\", split=\"val\")\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865bb594-a1f0-49af-bbe9-8d4567030356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_text', 'target_text'],\n",
       "    num_rows: 72831\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = load_dataset(\"wiki_bio\", split=\"test\")\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60389e0a-763f-4c48-b024-3981038f7f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_text', 'target_text'],\n",
       "        num_rows: 582659\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_text', 'target_text'],\n",
       "        num_rows: 72831\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_text', 'target_text'],\n",
       "        num_rows: 72831\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_dataset(\"wiki_bio\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa65cd0b-fa4f-496f-a3da-99358944a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default']\n"
     ]
    }
   ],
   "source": [
    "# check a list of all possible configurations available to my dataset\n",
    "from datasets import get_dataset_config_names\n",
    "configs = get_dataset_config_names(\"wiki_bio\")\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e13e6-5cd2-4843-9efe-b55b65cbe5b0",
   "metadata": {},
   "source": [
    "# 2. dataset과 iterabledataset의 차이\n",
    "\n",
    "### 엄청 큰 데이터셋의 경우 iterabledataset을 사용해서 전부 다운받을때까지 기다리지 않고 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ac9c61-fb16-4e8a-b4a4-2310d9153d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': {'table': {'column_header': ['name',\n",
       "    'nationality',\n",
       "    'occupation',\n",
       "    'article_title',\n",
       "    'birth_date'],\n",
       "   'row_number': [1, 1, 1, 1, 1],\n",
       "   'content': ['walter extra',\n",
       "    'german',\n",
       "    'aircraft designer and manufacturer',\n",
       "    'walter extra\\n',\n",
       "    '1954']},\n",
       "  'context': 'walter extra\\n'},\n",
       " 'target_text': 'walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\nextra was trained as a mechanical engineer .\\nhe began his flight training in gliders , transitioning to powered aircraft to perform aerobatics .\\nhe built and flew a pitts special aircraft and later built his own extra ea-230 .\\nextra began designing aircraft after competing in the 1982 world aerobatic championships .\\nhis aircraft constructions revolutionized the aerobatics flying scene and still dominate world competitions .\\nthe german pilot klaus schrodt won his world championship title flying an aircraft made by the extra firm .\\nwalter extra has designed a series of performance aircraft which include unlimited aerobatic aircraft and turboprop transports .\\n'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing\n",
    "d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b90bd8-d9fa-4280-97df-435f05adfdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': {'table': {'column_header': ['office',\n",
       "    'successor',\n",
       "    'district',\n",
       "    'name',\n",
       "    'predecessor',\n",
       "    'party',\n",
       "    'state_senate',\n",
       "    'residence',\n",
       "    'alma_mater',\n",
       "    'religion',\n",
       "    'article_title',\n",
       "    'profession',\n",
       "    'term_start',\n",
       "    'term_end'],\n",
       "   'row_number': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   'content': ['will county regional superintendent of schools',\n",
       "    'shawn walsh',\n",
       "    '49th',\n",
       "    'jennifer bertino-tarrant',\n",
       "    'new district richard p. duran',\n",
       "    'democratic',\n",
       "    'illinois',\n",
       "    'shorewood , illinois',\n",
       "    'loyola university',\n",
       "    'catholic',\n",
       "    'jennifer bertino-tarrant\\n',\n",
       "    'educator',\n",
       "    '2013 jan 2007 jul',\n",
       "    '2013 jan']},\n",
       "  'context': 'jennifer bertino-tarrant\\n'},\n",
       " 'target_text': 'jennifer bertino-tarrant is a member of the illinois senate for the 49th district .\\nthe 49th district includes all or part of bolingbrook , crest hill , joliet , oswego , plainfield , romeoville and shorewood .\\nprior to her service as an illinois state senator , she served as the will county superintendent of schools and as both and educator and administrator in public and private schools .\\n'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0003c86f-ba21-4d59-b8ea-33dcccf80bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table': {'column_header': ['name',\n",
       "   'nationality',\n",
       "   'occupation',\n",
       "   'article_title',\n",
       "   'birth_date'],\n",
       "  'row_number': [1, 1, 1, 1, 1],\n",
       "  'content': ['walter extra',\n",
       "   'german',\n",
       "   'aircraft designer and manufacturer',\n",
       "   'walter extra\\n',\n",
       "   '1954']},\n",
       " 'context': 'walter extra\\n'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[0][\"input_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c26f7-a90d-4e80-b094-ee88fb9d0b91",
   "metadata": {},
   "source": [
    "##### But it is important to remember that indexing order matters, especially when working with large audio and image datasets. Indexing by the column name returns all the values in the column first, then loads the value at that position. For large datasets, it may be slower to index by the column name first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d72086c6-cce2-45ad-95a3-867774ff3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "044b4466-94ba-4606-a7e9-e061d7c9652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0010 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "t1 = d1[0][\"input_text\"]\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0baaa152-b5de-4bfb-86d1-08b8a8361321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 33.3869 seconds\n"
     ]
    }
   ],
   "source": [
    "# 위에랑 다르게 얘는 전체 데이터셋들의 input_text 뽑아온 다음에 거기서 0번째 index 가져오기 때문에\n",
    "# 훨씬 느리다\n",
    "start_time = time.time()\n",
    "t1 = d1[\"input_text\"][0]\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "868b6a4c-5834-4d2f-ab53-93580a36df4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': [{'table': {'column_header': ['name',\n",
       "     'nationality',\n",
       "     'occupation',\n",
       "     'article_title',\n",
       "     'birth_date'],\n",
       "    'row_number': [1, 1, 1, 1, 1],\n",
       "    'content': ['walter extra',\n",
       "     'german',\n",
       "     'aircraft designer and manufacturer',\n",
       "     'walter extra\\n',\n",
       "     '1954']},\n",
       "   'context': 'walter extra\\n'},\n",
       "  {'table': {'column_header': ['birth_place',\n",
       "     'fullname',\n",
       "     'clubs',\n",
       "     'name',\n",
       "     'youthclubs',\n",
       "     'caps',\n",
       "     'position',\n",
       "     'pcupdate',\n",
       "     'article_title',\n",
       "     'years',\n",
       "     'goals',\n",
       "     'youthyears',\n",
       "     'birth_date',\n",
       "     'height'],\n",
       "    'row_number': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    'content': ['middleton , wisconsin , united states',\n",
       "     'aaron hohlbein',\n",
       "     'wisconsin fc -lrb- loan -rrb- fort lauderdale strikers badgers princeton 56ers kansas city wizards → miami',\n",
       "     'aaron hohlbein',\n",
       "     'wisconsin badgers',\n",
       "     '12 43 10 14',\n",
       "     'defender',\n",
       "     'june 4 , 2011',\n",
       "     'aaron hohlbein\\n',\n",
       "     '2003 -- 2006 2006 2007 -- 2010 2010 2011',\n",
       "     '0 2 0 0',\n",
       "     '2003 -- 2006',\n",
       "     '16 august 1985',\n",
       "     '6 0']},\n",
       "   'context': 'aaron hohlbein\\n'},\n",
       "  {'table': {'column_header': ['birth_place',\n",
       "     'death_cause',\n",
       "     'name',\n",
       "     'party',\n",
       "     'other_names',\n",
       "     'resting_place',\n",
       "     'nationality',\n",
       "     'death_place',\n",
       "     'education',\n",
       "     'death_date',\n",
       "     'known_for',\n",
       "     'alma_mater',\n",
       "     'occupation',\n",
       "     'article_title',\n",
       "     'image',\n",
       "     'birth_date'],\n",
       "    'row_number': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    'content': ['ljubljana , kingdom of yugoslavia',\n",
       "     'shot',\n",
       "     'majda vrhovnik',\n",
       "     'communist',\n",
       "     'lojzka',\n",
       "     'klagenfurt , austria',\n",
       "     'slovene',\n",
       "     'klagenfurt , nazi germany',\n",
       "     'medicine',\n",
       "     '04 may 1945',\n",
       "     \"people 's hero of yugoslavia\",\n",
       "     'faculty of medicine , university of ljubljana',\n",
       "     'espionage',\n",
       "     'majda vrhovnik\\n',\n",
       "     'majda vrhovnik.jpg',\n",
       "     '14 april 1922']},\n",
       "   'context': 'majda vrhovnik\\n'},\n",
       "  {'table': {'column_header': ['birth_place',\n",
       "     'name',\n",
       "     'occupation',\n",
       "     'article_title',\n",
       "     'birthname',\n",
       "     'birth_date'],\n",
       "    'row_number': [1, 1, 1, 1, 1, 1],\n",
       "    'content': ['stanmore , middlesex , england',\n",
       "     'linda hayden',\n",
       "     'actress',\n",
       "     'linda hayden\\n',\n",
       "     'linda m. higginson',\n",
       "     '19 january 1953']},\n",
       "   'context': 'linda hayden\\n'}],\n",
       " 'target_text': ['walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\nextra was trained as a mechanical engineer .\\nhe began his flight training in gliders , transitioning to powered aircraft to perform aerobatics .\\nhe built and flew a pitts special aircraft and later built his own extra ea-230 .\\nextra began designing aircraft after competing in the 1982 world aerobatic championships .\\nhis aircraft constructions revolutionized the aerobatics flying scene and still dominate world competitions .\\nthe german pilot klaus schrodt won his world championship title flying an aircraft made by the extra firm .\\nwalter extra has designed a series of performance aircraft which include unlimited aerobatic aircraft and turboprop transports .\\n',\n",
       "  'aaron hohlbein -lrb- born august 16 , 1985 in middleton , wisconsin -rrb- is an american soccer player who is currently without a club .\\n',\n",
       "  \"majda vrhovnik -lrb- nom de guerre lojzka -rrb- -lrb- 14 april 1922 -- 4 may 1945 -rrb- was a slovene communist and medical student .\\nshe was a member of the district committee of the communist party of slovenia for klagenfurt and was named a people 's hero of yugoslavia after her death .\\n\",\n",
       "  'linda hayden -lrb- born 19 january 1953 -rrb- is an english film and television actress and the sister of actress jane hayden .\\nshe is best known for her roles in 1970s british horror films and sex comedies .\\n']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e21e8-ca14-4123-b9ec-45461df30425",
   "metadata": {},
   "source": [
    "#### An IterableDataset is loaded when you set the streaming parameter to True in load_dataset():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da45b0c1-1628-48ee-b481-279e470d234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable_d1 = d1.to_iterable_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35df41-276a-4ccd-8eee-01d5020cfb38",
   "metadata": {},
   "source": [
    "#### You don’t get random access to examples in an IterableDataset. Instead, you should iterate over its elements, for example, by calling next(iter()) or with a for loop to return the next item from the IterableDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dceff7e3-94bb-41d2-bfb0-42327f766838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': {'table': {'column_header': ['name',\n",
       "    'nationality',\n",
       "    'occupation',\n",
       "    'article_title',\n",
       "    'birth_date'],\n",
       "   'row_number': [1, 1, 1, 1, 1],\n",
       "   'content': ['walter extra',\n",
       "    'german',\n",
       "    'aircraft designer and manufacturer',\n",
       "    'walter extra\\n',\n",
       "    '1954']},\n",
       "  'context': 'walter extra\\n'},\n",
       " 'target_text': 'walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\nextra was trained as a mechanical engineer .\\nhe began his flight training in gliders , transitioning to powered aircraft to perform aerobatics .\\nhe built and flew a pitts special aircraft and later built his own extra ea-230 .\\nextra began designing aircraft after competing in the 1982 world aerobatic championships .\\nhis aircraft constructions revolutionized the aerobatics flying scene and still dominate world competitions .\\nthe german pilot klaus schrodt won his world championship title flying an aircraft made by the extra firm .\\nwalter extra has designed a series of performance aircraft which include unlimited aerobatic aircraft and turboprop transports .\\n'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(iterable_d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70b5eebd-7bc7-4f04-a450-99264109fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_text': {'table': {'column_header': ['name', 'nationality', 'occupation', 'article_title', 'birth_date'], 'row_number': [1, 1, 1, 1, 1], 'content': ['walter extra', 'german', 'aircraft designer and manufacturer', 'walter extra\\n', '1954']}, 'context': 'walter extra\\n'}, 'target_text': 'walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\nextra was trained as a mechanical engineer .\\nhe began his flight training in gliders , transitioning to powered aircraft to perform aerobatics .\\nhe built and flew a pitts special aircraft and later built his own extra ea-230 .\\nextra began designing aircraft after competing in the 1982 world aerobatic championships .\\nhis aircraft constructions revolutionized the aerobatics flying scene and still dominate world competitions .\\nthe german pilot klaus schrodt won his world championship title flying an aircraft made by the extra firm .\\nwalter extra has designed a series of performance aircraft which include unlimited aerobatic aircraft and turboprop transports .\\n'}\n"
     ]
    }
   ],
   "source": [
    "for example in iterable_d1:\n",
    "    print(example)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ada7e87e-c986-42f7-9d53-e8f7d7e49e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_text': {'table': {'column_header': ['name',\n",
       "     'nationality',\n",
       "     'occupation',\n",
       "     'article_title',\n",
       "     'birth_date'],\n",
       "    'row_number': [1, 1, 1, 1, 1],\n",
       "    'content': ['walter extra',\n",
       "     'german',\n",
       "     'aircraft designer and manufacturer',\n",
       "     'walter extra\\n',\n",
       "     '1954']},\n",
       "   'context': 'walter extra\\n'},\n",
       "  'target_text': 'walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\nextra was trained as a mechanical engineer .\\nhe began his flight training in gliders , transitioning to powered aircraft to perform aerobatics .\\nhe built and flew a pitts special aircraft and later built his own extra ea-230 .\\nextra began designing aircraft after competing in the 1982 world aerobatic championships .\\nhis aircraft constructions revolutionized the aerobatics flying scene and still dominate world competitions .\\nthe german pilot klaus schrodt won his world championship title flying an aircraft made by the extra firm .\\nwalter extra has designed a series of performance aircraft which include unlimited aerobatic aircraft and turboprop transports .\\n'},\n",
       " {'input_text': {'table': {'column_header': ['birth_place',\n",
       "     'fullname',\n",
       "     'clubs',\n",
       "     'name',\n",
       "     'youthclubs',\n",
       "     'caps',\n",
       "     'position',\n",
       "     'pcupdate',\n",
       "     'article_title',\n",
       "     'years',\n",
       "     'goals',\n",
       "     'youthyears',\n",
       "     'birth_date',\n",
       "     'height'],\n",
       "    'row_number': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    'content': ['middleton , wisconsin , united states',\n",
       "     'aaron hohlbein',\n",
       "     'wisconsin fc -lrb- loan -rrb- fort lauderdale strikers badgers princeton 56ers kansas city wizards → miami',\n",
       "     'aaron hohlbein',\n",
       "     'wisconsin badgers',\n",
       "     '12 43 10 14',\n",
       "     'defender',\n",
       "     'june 4 , 2011',\n",
       "     'aaron hohlbein\\n',\n",
       "     '2003 -- 2006 2006 2007 -- 2010 2010 2011',\n",
       "     '0 2 0 0',\n",
       "     '2003 -- 2006',\n",
       "     '16 august 1985',\n",
       "     '6 0']},\n",
       "   'context': 'aaron hohlbein\\n'},\n",
       "  'target_text': 'aaron hohlbein -lrb- born august 16 , 1985 in middleton , wisconsin -rrb- is an american soccer player who is currently without a club .\\n'},\n",
       " {'input_text': {'table': {'column_header': ['birth_place',\n",
       "     'death_cause',\n",
       "     'name',\n",
       "     'party',\n",
       "     'other_names',\n",
       "     'resting_place',\n",
       "     'nationality',\n",
       "     'death_place',\n",
       "     'education',\n",
       "     'death_date',\n",
       "     'known_for',\n",
       "     'alma_mater',\n",
       "     'occupation',\n",
       "     'article_title',\n",
       "     'image',\n",
       "     'birth_date'],\n",
       "    'row_number': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "    'content': ['ljubljana , kingdom of yugoslavia',\n",
       "     'shot',\n",
       "     'majda vrhovnik',\n",
       "     'communist',\n",
       "     'lojzka',\n",
       "     'klagenfurt , austria',\n",
       "     'slovene',\n",
       "     'klagenfurt , nazi germany',\n",
       "     'medicine',\n",
       "     '04 may 1945',\n",
       "     \"people 's hero of yugoslavia\",\n",
       "     'faculty of medicine , university of ljubljana',\n",
       "     'espionage',\n",
       "     'majda vrhovnik\\n',\n",
       "     'majda vrhovnik.jpg',\n",
       "     '14 april 1922']},\n",
       "   'context': 'majda vrhovnik\\n'},\n",
       "  'target_text': \"majda vrhovnik -lrb- nom de guerre lojzka -rrb- -lrb- 14 april 1922 -- 4 may 1945 -rrb- was a slovene communist and medical student .\\nshe was a member of the district committee of the communist party of slovenia for klagenfurt and was named a people 's hero of yugoslavia after her death .\\n\"}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first 3 examples\n",
    "# But unlike slicing, IterableDataset.take() creates a new IterableDataset.\n",
    "list(iterable_d1.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1669616-e2c3-48ea-970d-939eaccf74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col_1': 0}\n"
     ]
    }
   ],
   "source": [
    "my_dataset = d1.from_dict({\"col_1\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]})\n",
    "print(my_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5cfe090-d7b2-436c-9740-ee9547b196fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col_1': 0}\n"
     ]
    }
   ],
   "source": [
    "def my_generator(n):\n",
    "    for i in range(n):\n",
    "        yield {\"col_1\": i}\n",
    "\n",
    "my_iterable_dataset = iterable_d1.from_generator(my_generator, gen_kwargs={\"n\": 10})\n",
    "for example in my_iterable_dataset:\n",
    "    print(example)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "169689ef-fcc3-4c86-ac07-9f14a862fe94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실제 사용하고자 하는 process_fn 넣어야함.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 근데 언제쓰는지 명확하게 감은 안옴 아직은.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m my_dataset_new \u001b[38;5;241m=\u001b[39m my_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[43mprocess_fn\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_dataset_new[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_fn' is not defined"
     ]
    }
   ],
   "source": [
    "# 실제 사용하고자 하는 process_fn 넣어야함.\n",
    "# 근데 언제쓰는지 명확하게 감은 안옴 아직은.\n",
    "my_dataset_new = my_dataset.map(process_fn)\n",
    "print(my_dataset_new[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceec4b-4238-44b2-85b0-480b6bb92024",
   "metadata": {},
   "source": [
    "# 3. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0739502-e46b-4553-971a-f51fe4e55aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "     ---------------------------------------- 0.0/123.5 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/123.5 kB ? eta -:--:--\n",
      "     --------- --------------------------- 30.7/123.5 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 123.5/123.5 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.10.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.0-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp311-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jds\\.conda\\envs\\huggingface\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.6/7.9 MB 35.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.6/7.9 MB 39.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.7/7.9 MB 33.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.9/7.9 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 33.8 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.6/269.6 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.1-cp311-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 277.5/277.5 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.0-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.2 MB 14.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 14.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2023.10.3 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969c4e4a-2e61-4888-8b08-06944106cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30661b48-7151-4790-9001-23f2e0a7c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = load_dataset(\"wiki_bio\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594e8742-8ea5-4cd0-aaaa-52b0e1111f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset[0][\"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c1d070-93c3-4dd1-9084-60cb61f69c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 4787, 4469, 2003, 1037, 2446, 2400, 1011, 3045, 18440, 14479, 2594, 4405, 1010, 2708, 2948, 5859, 1998, 3910, 1997, 4469, 19857, 2290, 4371, 15916, 27773, 1011, 1048, 15185, 1011, 4469, 2948, 2810, 1011, 25269, 2497, 1011, 1010, 1037, 7751, 1997, 18440, 14479, 2594, 2948, 1012, 4469, 2001, 4738, 2004, 1037, 6228, 3992, 1012, 2002, 2211, 2010, 3462, 2731, 1999, 18788, 2015, 1010, 6653, 2075, 2000, 6113, 2948, 2000, 4685, 18440, 14479, 6558, 1012, 2002, 2328, 1998, 5520, 1037, 15091, 2015, 2569, 2948, 1998, 2101, 2328, 2010, 2219, 4469, 19413, 1011, 11816, 1012, 4469, 2211, 12697, 2948, 2044, 6637, 1999, 1996, 3196, 2088, 18440, 14479, 2594, 3219, 1012, 2010, 2948, 21913, 4329, 3550, 1996, 18440, 14479, 6558, 3909, 3496, 1998, 2145, 16083, 2088, 6479, 1012, 1996, 2446, 4405, 16536, 8040, 8093, 7716, 2102, 2180, 2010, 2088, 2528, 2516, 3909, 2019, 2948, 2081, 2011, 1996, 4469, 3813, 1012, 4787, 4469, 2038, 2881, 1037, 2186, 1997, 2836, 2948, 2029, 2421, 14668, 18440, 14479, 2594, 2948, 1998, 15386, 21572, 2361, 19003, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tokenizer returns a dictionary with three items:\n",
    "# input_ids: the numbers representing the tokens in the text.\n",
    "# token_type_ids: indicates which sequence a token belongs to if there is more than one sequence.\n",
    "# attention_mask: indicates whether a token should be masked or not.\n",
    "\n",
    "tokenizer(dataset[0][\"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e199143-5dab-4675-99e4-0703ce0170a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7173b73-e8f0-4817-bc66-2f3a204e7efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5126066205a44915b76b811fc060aa50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/582659 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def tokenization(example):\n",
    "    return tokenizer(example[\"target_text\"])\n",
    "\n",
    "dataset = dataset.map(tokenization, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c36add01-0086-4df2-988d-dd188f872d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"])\n",
    "dataset.format['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14f686-a4f6-450d-871b-9637aa4f864f",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "\n",
    "##### 근데 지금은 안쓰고 아래 링크 공부하라고함.\n",
    "##### https://huggingface.co/docs/evaluate/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38e16ee8-b41f-43da-a0de-2ebba85b2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12c9afe-5fa3-4858-b253-49ba3b56a0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "['accuracy', 'bertscore', 'bleu', 'bleurt', 'brier_score', 'cer', 'character', 'charcut_mt', 'chrf', 'code_eval', 'comet', 'competition_math', 'coval', 'cuad', 'exact_match', 'f1', 'frugalscore', 'glue', 'google_bleu', 'indic_glue', 'mae', 'mahalanobis', 'mape', 'mase', 'matthews_correlation', 'mauve', 'mean_iou', 'meteor', 'mse', 'nist_mt', 'pearsonr', 'perplexity', 'poseval', 'precision', 'r_squared', 'recall', 'rl_reliability', 'roc_auc', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'smape', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'ter', 'trec_eval', 'wer', 'wiki_split', 'xnli', 'xtreme_s', 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics', 'BucketHeadP65/confusion_matrix', 'BucketHeadP65/roc_curve', 'DarrenChensformer/eval_keyphrase', 'DarrenChensformer/relation_extraction', 'Drunper/metrica_tesi', 'Felipehonorato/eer', 'GMFTBY/dailydialog_evaluate', 'GMFTBY/dailydialogevaluate', 'He-Xingwei/sari_metric', 'Ikala-allen/relation_extraction', 'JP-SystemsX/nDCG', 'Josh98/nl2bash_m', 'KevinSpaghetti/accuracyk', 'Muennighoff/code_eval_octopack', 'NCSOFT/harim_plus', 'Natooz/ece', 'NikitaMartynov/spell-check-metric', 'NimaBoscarino/weat', 'Ochiroo/rouge_mn', 'Pipatpong/perplexity', 'SpfIo/wer_checker', 'Splend1dchan/cosine_similarity', 'Vallp/ter', 'Vertaix/vendiscore', 'Viona/fuzzy_reordering', 'Viona/infolm', 'Viona/kendall_tau', 'Vipitis/shadermatch', 'Vlasta/pr_auc', 'Yeshwant123/mcc', 'abdusah/aradiawer', 'abidlabs/mean_iou', 'abidlabs/mean_iou2', 'amitness/perplexity', 'andstor/code_perplexity', 'angelina-wang/directional_bias_amplification', 'anz2/iliauniiccocrevaluation', 'aryopg/roc_auc_skip_uniform_labels', 'bdsaglam/jer', 'brian920128/doc_retrieve_metrics', 'bstrai/classification_report', 'bugbounty1806/accuracy', 'cakiki/ndcg', 'carletoncognitivescience/peak_signal_to_noise_ratio', 'chanelcolgate/average_precision', 'ckb/unigram', 'codeparrot/apps_metric', 'cpllab/syntaxgym', 'daiyizheng/valid', 'danieldux/hierarchical_softmax_loss', 'dvitel/codebleu', 'ecody726/bertscore', 'erntkn/dice_coefficient', 'fnvls/bleu1234', 'fnvls/bleu_1234', 'fschlatt/ner_eval', 'gabeorlanski/bc_eval', 'giulio98/code_eval_outputs', 'giulio98/codebleu', 'gjacob/wiki_split', 'gnail/cosine_similarity', 'gorkaartola/metric_for_tp_fp_samples', 'guydav/restrictedpython_code_eval', 'hack/test_metric', 'harshhpareek/bertscore', 'hpi-dhc/FairEval', 'hynky/sklearn_proxy', 'hyperml/balanced_accuracy', 'idsedykh/codebleu', 'idsedykh/codebleu2', 'idsedykh/megaglue', 'idsedykh/metric', 'illorca/FairEval', 'ingyu/klue_mrc', 'jjkim0807/code_eval', 'jordyvl/ece', 'jpxkqx/peak_signal_to_noise_ratio', 'jpxkqx/signal_to_reconstruction_error', 'jzm-mailchimp/joshs_second_test_metric', 'k4black/codebleu', 'kashif/mape', 'kedudzic/charmatch', 'kyokote/my_metric2', 'langdonholmes/cohen_weighted_kappa', 'leslyarun/fbeta_score', 'lhy/hamming_loss', 'lhy/ranking_loss', 'loubnabnl/apps_metric2', 'lvwerra/accuracy_score', 'lvwerra/bary_score', 'lvwerra/test', 'manueldeprada/beer', 'mfumanelli/geometric_mean', 'mgfrantz/roc_auc_macro', 'mtc/fragments', 'nevikw39/specificity', 'nlpln/tst', 'ola13/precision_at_k', 'omidf/squad_precision_recall', 'posicube/mean_reciprocal_rank', 'repllabs/mean_average_precision', 'repllabs/mean_reciprocal_rank', 'ronaldahmed/nwentfaithfulness', 'sakusakumura/bertscore', 'shalakasatheesh/squad', 'shalakasatheesh/squad_v2', 'shirayukikun/sescore', 'shunzh/apps_metric', 'sma2023/wil', 'sportlosos/sescore', 'tialaeMceryu/unigram', 'transZ/sbert_cosine', 'transZ/test_parascore', 'transformersegmentation/segmentation_scores', 'unitxt/metric', 'unnati/kendall_tau_distance', 'vichyt/metric-codebleu', 'weiqis/pajm', 'xu1998hz/sescore', 'xu1998hz/sescore_english_coco', 'xu1998hz/sescore_english_mt', 'xu1998hz/sescore_english_webnlg', 'xu1998hz/sescore_german_mt', 'ybelkada/cocoevaluate', 'yonting/average_precision_score', 'yqsong/execution_accuracy', 'yulong-me/yl_metric', 'yuyijiong/quad_match_score', 'yzha/ctc_eval', 'zbeloki/m2']\n"
     ]
    }
   ],
   "source": [
    "metrics_list = list_metrics()\n",
    "print(len(metrics_list))\n",
    "print(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a164a45c-e08c-4e09-add2-cfe2ad22647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('glue', 'mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed548a68-c5aa-41f8-b1c6-40f8482854ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
      "Args:\n",
      "    predictions: list of predictions to score.\n",
      "        Each translation should be tokenized into a list of tokens.\n",
      "    references: list of lists of references for each translation.\n",
      "        Each reference should be tokenized into a list of tokens.\n",
      "Returns: depending on the GLUE subset, one or several of:\n",
      "    \"accuracy\": Accuracy\n",
      "    \"f1\": F1 score\n",
      "    \"pearson\": Pearson Correlation\n",
      "    \"spearmanr\": Spearman Correlation\n",
      "    \"matthews_correlation\": Matthew Correlation\n",
      "Examples:\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'accuracy': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'accuracy': 1.0, 'f1': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
      "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
      "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
      "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
      "\n",
      "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
      "    >>> references = [0, 1]\n",
      "    >>> predictions = [0, 1]\n",
      "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'matthews_correlation': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metric.inputs_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a729d95-fa06-4747-be53-203787a7a6b1",
   "metadata": {},
   "source": [
    "# 5. Create a dataset\n",
    "\n",
    "#### 1) Folder-based builders for quickly creating an image or audio dataset\n",
    "#### 2) from_ methods for creating datasets from local files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30a420a2-8398-466b-8512-141d63359fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기 잘 이해가 안됨\n",
    "# 그리고 audio, image 위주로 설명하고 있음\n",
    "# 이거 보면 되려나?\n",
    "# https://huggingface.co/docs/datasets/main/en/dataset_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6b5d3-52f5-4fcf-9b01-4a751c68881c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c5fbd9-5ea6-447a-835b-a87d76b68b1c",
   "metadata": {},
   "source": [
    "# 6. Share a dataset to the Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2ff8e-37c3-45d1-8351-74dc19bc7924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80c4901-5c6a-4be8-9938-4959b8acd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebook git clone 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9137ca-feb1-413c-b572-a92207ff6d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb90be2-6b0b-42b5-8a43-c99b0786780a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ceede-373d-46f4-ae07-9298fa9406a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4157c-5158-46cb-9386-e5aaf26f9b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f5b9e-6a3f-4538-97b2-988739131a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3d259-2d43-4474-867b-a928df59f85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77292b8c-dd89-4c2c-8d33-4154ee063142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b1cee-6185-4bf3-8103-0fe557c22fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7edda-03b0-4096-816b-827c2f8e63e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61027bf2-30fa-44e0-9d67-adc996e8c820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bab46e-0e70-40b3-bd3c-6383b5fe06f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd5031-eba0-492b-96e1-d39a0b8dc176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a5834-3f21-4024-99db-718ecc7f9fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f82b310-6b13-435c-98f5-69af11a9134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf4275-4159-47a4-9a7b-e699e374bd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d57a2-50c6-4e82-b71a-ab87b69f5814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14035939-9939-4b69-9b31-a2f3d5f7b3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b15bd8-33c2-45f9-88f2-de7030a63025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6fcdf-f44a-4126-900b-d333b4755211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bdfd8-c209-4bc0-a67e-13cb3337dfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a10ee2-fc2c-4f03-a997-56696195569d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c9d83-98ae-4efb-a3d4-797ba2798330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
